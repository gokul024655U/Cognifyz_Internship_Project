"""Cognify task

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1XTbgRl_mL7NE7HV_95vV0Va3bfiJpDdS
"""
#cognify level 3(task 1)
# Task: Predictive Modeling

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.express as px
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.tree import DecisionTreeRegressor
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error, r2_score

# Load the dataset
df = pd.read_csv('Dataset .csv')

# Build a regression model to predict the aggregate rating of a restaurant based on available features.

# Convert necessary columns to numeric
df['Aggregate rating'] = pd.to_numeric(df['Aggregate rating'], errors='coerce')
df['Votes'] = pd.to_numeric(df['Votes'], errors='coerce')
df['Price range'] = pd.to_numeric(df['Price range'], errors='coerce')
df['Has Table Booking'] = df['Has Table booking'].apply(lambda x: 1 if x == 'Yes' else 0)
df['Has Online Delivery'] = df['Is delivering now'].apply(lambda x: 1 if x == 'Yes' else 0)

# Select features and target
features = ['Votes', 'Price range', 'Has Table Booking', 'Has Online Delivery']
target = 'Aggregate rating'

# Remove rows with missing values
df_model = df[features + [target]].dropna()

X = df_model[features]
y = df_model[target]

# Build regression model (just training, no evaluation here)
model = LinearRegression()
model.fit(X, y)
# Print confirmation
print("âœ… Regression model has been successfully built and trained.")


#Split the dataset into training and testing sets and evaluate the model's performance using appropriate metrics

# Split the dataset into train and test
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Train model again using training set
model = LinearRegression()
model.fit(X_train, y_train)

# Predict using the test set
y_pred = model.predict(X_test)

# Evaluate model
mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

# Print the evaluation
print("âœ… Model Evaluation Metrics:\n")
print(f"Mean Squared Error (MSE): {mse:.2f}")
print(f"R-squared Score: {r2:.2f}")


# Experiment with different algorithms (e.g.,linear regression, decision trees, random forest) and compare their performance
# Step 1: Preprocess - Convert necessary columns
df['Aggregate rating'] = pd.to_numeric(df['Aggregate rating'], errors='coerce')
df['Votes'] = pd.to_numeric(df['Votes'], errors='coerce')
df['Price range'] = pd.to_numeric(df['Price range'], errors='coerce')

# Step 2: Encode Yes/No columns
df['Has Table Booking'] = df['Has Table booking'].apply(lambda x: 1 if x == 'Yes' else 0)
df['Has Online Delivery'] = df['Is delivering now'].apply(lambda x: 1 if x == 'Yes' else 0)

# Step 3: Select features and target
features = ['Votes', 'Price range', 'Has Table Booking', 'Has Online Delivery']
target = 'Aggregate rating'

# Step 4: Clean data
df_model = df[features + [target]].dropna()
X = df_model[features]
y = df_model[target]

# Step 5: Split into training and testing
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Step 6: Define models
models = {
    "Linear Regression": LinearRegression(),
    "Decision Tree": DecisionTreeRegressor(random_state=42),
    "Random Forest": RandomForestRegressor(random_state=42)
}

# Step 7: Train and evaluate each model
print("âœ… Model Comparison:\n")
for name, model in models.items():
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)

    mse = mean_squared_error(y_test, y_pred)
    r2 = r2_score(y_test, y_pred)

    print(f"{name}:\n  ðŸ”¹ Mean Squared Error: {mse:.2f}\n  ðŸ”¹ RÂ² Score: {r2:.2f}\n")

